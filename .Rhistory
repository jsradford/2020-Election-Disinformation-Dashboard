count (word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes (x=reorder (word, n), y=n)) +
geom_col() +
coord_flip() +
labs(x="Word", y="Count",
title="Trump Tweets") +
scale_fill_brewer (palette="Setl")
tidyTrump_2015_2020 %>%
group_by (year) %>%
count (word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes (x=reorder_within(word, n, year), y=n, fill = year)) +
geom_col(show.legend = FALSE) +
facet_wrap(-year, scales="free") +
coord_flip() +
labs(x="Words", y="Count",
title="Trumps Most common words by year") +
scale_fill_brewer (palette="Setl") +
scale_x_reordered()
tidyTrump_2015_2020 %>%
group_by(year) %>%
count (word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes (x=reorder_within(word, n, year), y=n, fill = year)) +
geom_col(show.legend = FALSE) +
facet_wrap(-year, scales="free") +
coord_flip() +
labs(x="Words", y="Count",
title="Trumps Most common words by year") +
scale_fill_brewer (palette="Setl") +
scale_x_reordered()
as_tibble(tidyTrump_2015_2020)
tidyTrump_2015_2020 %>%
group_by(year) %>%
count (word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes (x=reorder_within(word, n, year), y=n, fill = year)) +
geom_col(show.legend = FALSE) +
facet_wrap(-year, scales="free") +
coord_flip() +
labs(x="Words", y="Count",
title="Trumps Most common words by year") +
scale_fill_brewer (palette="Setl") +
scale_x_reordered()
data <- read.csv("twitter/realDonaldTrump-20201106.csv")
#as_tibble(data)
tidyTrump <- data %>%
filter(isRetweet == 'f') %>%
unnest_tokens (input = text, output = "word", token = "tweets", strip_url = TRUE) %>%
anti_join(stop_words, by = "word") %>%
filter(!str_detect(word, 'realdonaldtrump')) %>%
filter(!str_detect(word, 'donald')) %>%
filter(!str_detect(word, 'trump')) %>%
filter(!str_detect(word, '[:space:]')) %>%
filter(!str_detect (word, "@")) %>%
filter(!str_detect(word, "https")) %>%
filter(!str_detect (word, "&amp")) %>%
filter (!str_detect(word, "amp"))
as_tibble(tidyTrump)
tidyTrump %>%
count (word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes (x=reorder (word, n), y=n)) +
geom_col() +
coord_flip() +
labs(x="Word", y="Count",
title="Trump Tweets") +
scale_fill_brewer (palette="Setl")
tidyTrump_2015_2020 <- tidyTrump %>% mutate(year=substr(tidyTrump$date,1,4)) %>%
filter(year %in% c('2015','2016','2017','2018','2019','2020'))
tidyTrump_2015_2020 %>%
group_by(year) %>%
count (word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes (x=reorder_within(word, n, year), y=n, fill = year)) +
geom_col(show.legend = FALSE) +
facet_wrap(-year, scales="free") +
coord_flip() +
labs(x="Words", y="Count",
title="Trumps Most common words by year") +
scale_fill_brewer (palette="Setl") +
scale_x_reordered()
tidyTrump_2015_2020 <- tidyTrump %>% mutate(year=substr(tidyTrump$date,1,4)) %>%
filter(year %in% c('2015','2016','2017','2018','2019','2020'))
as_tibble(tidyTrump_2015_2020)
tidyTrump_2015_2020 %>%
group_by(year) %>%
count (word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes (x=reorder_within(word, n, year), y=n, fill = year)) +
geom_col(show.legend = FALSE) +
facet_wrap(-year, scales="free") +
coord_flip() +
labs(x="Words", y="Count",
title="Trumps Most common words by year") +
scale_fill_brewer (palette="Setl") +
scale_x_reordered()
tidyTrump_2015_2020 <- tidyTrump %>% mutate(year=substr(tidyTrump$date,1,4)) %>%
filter(year %in% c('2015','2016','2017','2018','2019','2020'))
as_tibble(tidyTrump_2015_2020)
tidyTrump_2015_2020 %>%
group_by(year) %>%
count (word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes (x=reorder_within(word, n, year), y=n, fill = year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~year, scales="free") +
coord_flip() +
labs(x="Words", y="Count",
title="Trumps Most common words by year") +
scale_fill_brewer (palette="Setl") +
scale_x_reordered()
tidyTrump_2015_2020 <- tidyTrump %>% mutate(year=substr(tidyTrump$date,1,4)) %>%
filter(year %in% c('2015','2016','2017','2018','2019','2020'))
as_tibble(tidyTrump_2015_2020)
tidyTrump_2015_2020 %>%
group_by(year) %>%
count (word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes (x=reorder_within(word, n, year), y=n, fill = year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~year, scales="free") +
coord_flip() +
labs(x="Words", y="Count",
title="Trumps Most common words by year") +
scale_fill_brewer (palette="Set1") +
scale_x_reordered()
library(tidyverse)
library(sotu)
library(dplyr)
library(stringr)
library(tidytext)
#Problem 1
data <- read.csv("twitter/realDonaldTrump-20201106.csv")
#Remove Retweets
data_1 <- data %>% filter(isRetweet=="f")
#Remove tweets with no space
data_2 <- data_1 %>% mutate(spaceRT=str_replace_all(data_1$text," ",""))
data_3 <- data_2 %>%
transmute(id,text,date,noSpace=if_else(data_2$text==data_2$spaceRT,"T","F")) %>%
filter(noSpace !="T")
#Remove URLs and @username
data_3 <- select(data_3,id,date,text)
data_tidy <- unnest_tokens(data_3,output="word",input=text,
token = stringr::str_split, pattern = " ")
data_tidy0 <- data_tidy %>% mutate(URL = str_detect(data_tidy$word,"http"),
at= str_detect(data_tidy$word,"@")) %>%
filter(URL==FALSE & at==FALSE) %>% select(id,date,word)
#Remove &amp and Hashtags
data_tidy1 <- data_tidy0 %>% filter(!str_detect(word,'&amp')) %>%
filter(!str_detect(word,'#'))
#Remove stop words
data_tidy2 <- anti_join(data_tidy1, stop_words, by="word")
#Remove special characters from word
data_tidy3 <- data_tidy2 %>%
mutate(word=str_replace_all(data_tidy2$word,"[^[:alnum:]]", ""))
#Remove stop words again
data_tidy3 <- anti_join(data_tidy3, stop_words, by="word")
#remove blanks and special characters
data_tidy4 <- data_tidy3 %>% filter(!str_trim(data_tidy3$word) %in% c('','-'))
#remove variations of Donald Trump
data_tidy5 <- data_tidy4 %>%
filter(!str_detect(tolower(word),'donald')) %>%
filter(!str_detect(tolower(word),'trump')) %>%
filter(!str_detect(tolower(word),'donÃ¢'))
#Plot
data_tidy5 %>%
count(word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes(x=reorder(word, n), y=n)) +
geom_col() +
coord_flip() +
labs(x="Word", y="Count",
title="Trump Tweets") +
theme_minimal()
#Problem 2
#Filter on Year 2015-2020
data_tidy_6 <- data_tidy5 %>% mutate(year=substr(data_tidy5$date,1,4)) %>%
filter(year %in% c('2015','2016','2017','2018','2019','2020'))
data_tidy_6 %>%
filter(str_detect(word, "[:alpha:]")) %>%
count(word,year, sort=TRUE) %>%
group_by(year) %>%
top_n(20) %>%
ggplot(aes(x=reorder_within(word,n,year), y=n,fill=year)) +
geom_col(show.legend=FALSE) +
coord_flip() +
facet_wrap(~year,scales="free")+
labs(x="Word", y="Count",
title="Trump Tweets") +
scale_fill_brewer(palette="Dark2") +
scale_x_reordered() +
theme_minimal()
#Problem 3
#tf-idf
#calculate tf
data_tfidf <- data_tidy_6 %>% count(year, word, sort=TRUE) %>%
bind_tf_idf(term=word, document=year, n=n)
data_tfidf %>%
filter(str_detect(word, "[:alpha:]")) %>%
group_by(year) %>%
top_n(10, wt=tf_idf) %>%
ggplot(aes(x=reorder_within(word, tf_idf, year), y=tf_idf, fill=year)) +
geom_col(show.legend=FALSE) +
facet_wrap(~year, scales="free") +
coord_flip() +
labs(x="Word", y="tf-idf",
title="Trump Tweets: Most defining words (by Year)",
fill="Year") +
scale_fill_brewer(palette="Dark2") +
scale_x_reordered() +
scale_y_continuous(labels=NULL) +
theme_minimal()
tweetsTrumpTidy_2015_2020_tf_idf <- tidyTrump_2015_2020 %>%
count(year, word, sort=TRUE) %>%
bind_tf_idf(term=word, document=year, n=n)
arrange (tweetsTrumpTidy_2015_2020_tf_idf, desc(tf_idf))
tweetsTrumpTidy_2015_2020_tf_idf %>%
group_by(year) %>%
top_n(20, wt=tf_idf) %>%
ggplot(aes (x=reorder_within(word, tf_idf, year), y=tf_idf, fill-year)) +
geom_col(show.legend=FALSE) +
theme(axis.text.x-element_blank(),
axis.ticks.x=element_blank()) +
facet_wrap(-year, scales="free") +
coord_flip() +
labs(x="Word", y="TF-IDF",
title="Top 20 most frequent tweets",
fill="Time Period") +
scale_fill_brewer (palette="Setl") +
scale_x_reordered() +
theme(axis.text.y = element_text(size=8))
tweetsTrumpTidy_2015_2020_tf_idf <- tidyTrump_2015_2020 %>%
count(year, word, sort=TRUE) %>%
bind_tf_idf(term=word, document=year, n=n)
arrange (tweetsTrumpTidy_2015_2020_tf_idf, desc(tf_idf))
tweetsTrumpTidy_2015_2020_tf_idf %>%
group_by(year) %>%
top_n(20, wt=tf_idf) %>%
ggplot(aes (x=reorder_within(word, tf_idf, year), y=tf_idf, fill-year)) +
geom_col(show.legend=FALSE) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank()) +
facet_wrap(-year, scales="free") +
coord_flip() +
labs(x="Word", y="TF-IDF",
title="Top 20 most frequent tweets",
fill="Time Period") +
scale_fill_brewer (palette="Setl") +
scale_x_reordered() +
theme(axis.text.y = element_text(size=8))
tweetsTrumpTidy_2015_2020_tf_idf <- tidyTrump_2015_2020 %>%
count(year, word, sort=TRUE) %>%
bind_tf_idf(term=word, document=year, n=n)
arrange (tweetsTrumpTidy_2015_2020_tf_idf, desc(tf_idf))
tweetsTrumpTidy_2015_2020_tf_idf %>%
group_by(year) %>%
top_n(20, wt=tf_idf) %>%
ggplot(aes (x=reorder_within(word, tf_idf, year), y=tf_idf, fill-year)) +
geom_col(show.legend=FALSE) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank()) +
facet_wrap(~year, scales="free") +
coord_flip() +
labs(x="Word", y="TF-IDF",
title="Top 20 most frequent tweets",
fill="Time Period") +
scale_fill_brewer (palette="Setl") +
scale_x_reordered() +
theme(axis.text.y = element_text(size=8))
tweetsTrumpTidy_2015_2020_tf_idf <- tidyTrump_2015_2020 %>%
count(year, word, sort=TRUE) %>%
bind_tf_idf(term=word, document=year, n=n)
arrange (tweetsTrumpTidy_2015_2020_tf_idf, desc(tf_idf))
tweetsTrumpTidy_2015_2020_tf_idf %>%
group_by(year) %>%
top_n(20, wt=tf_idf) %>%
ggplot(aes (x=reorder_within(word, tf_idf, year), y=tf_idf, fill-year)) +
geom_col(show.legend=FALSE) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank()) +
facet_wrap(~year, scales="free") +
coord_flip() +
labs(x="Word", y="TF-IDF",
title="Top 20 most frequent tweets",
fill="Time Period") +
scale_fill_brewer (palette="Set1") +
scale_x_reordered() +
theme(axis.text.y = element_text(size=8))
tweetsTrumpTidy_2015_2020_tf_idf <- tidyTrump_2015_2020 %>%
count(year, word, sort=TRUE) %>%
bind_tf_idf(term=word, document=year, n=n)
arrange (tweetsTrumpTidy_2015_2020_tf_idf, desc(tf_idf))
tweetsTrumpTidy_2015_2020_tf_idf %>%
group_by(year) %>%
top_n(20, wt=tf_idf) %>%
ggplot(aes (x=reorder_within(word, tf_idf, year), y=tf_idf, fill-year)) +
geom_col(show.legend=FALSE) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank()) +
facet_wrap(~year, scales="free") +
coord_flip() +
labs(x="Word", y="TF-IDF",
title="Top 20 most frequent tweets",
fill="Time Period") +
scale_fill_brewer(palette="Set1") +
scale_x_reordered() +
theme(axis.text.y = element_text(size=8))
library(glmnet)
#Filter on Year 2016-2020
dataTidy <- tidyTrump %>% mutate(year=substr(tidyTrump$date,1,4)) %>%
filter(year %in% c('2016','2017','2018','2019','2020'))
dataTidyRows <- tibble(id = rownames(dataTidy))
trumpTweetsFull <- left_join(dataTidyRows, data)
library(glmnet)
#Filter on Year 2016-2020
#dataTidy <- tidyTrump %>% mutate(year=substr(tidyTrump$date,1,4)) %>%
#          filter(year %in% c('2016','2017','2018','2019','2020'))
dataTidy <- tidyTrump %>%
filter(date >= 2016) %>%
count(id, word) %>%
cast_sparse(id, word, n)
dataTidyRows <- tibble(id = rownames(dataTidy))
trumpTweetsFull <- left_join(dataTidyRows, data)
library(glmnet)
#Filter on Year 2016-2020
#dataTidy <- tidyTrump %>% mutate(year=substr(tidyTrump$date,1,4)) %>%
#          filter(year %in% c('2016','2017','2018','2019','2020'))
dataTidy <- tidyTrump %>%
filter(date >= 2016) %>%
count(id, word) %>%
cast_sparse(id, word, n)
dataTidyRows <- transform(dataTidy, id = as.double(id))
library(glmnet)
#Filter on Year 2016-2020
dataTidy <- data %>% mutate(year=substr(tidyTrump$date,1,4)) %>%
filter(year %in% c('2016','2017','2018','2019','2020'))
library(glmnet)
#Filter on Year 2016-2020
dataTidy <- data %>% mutate(year=substr(data$date,1,4)) %>%
filter(year %in% c('2016','2017','2018','2019','2020'))
as_tibble(dataTidy)
fit1 <- glmnet(dataTidy, dataTidy$retweets)
plot(fit1, xvar = "lambda", label = TRUE)
library(glmnet)
#Filter on Year 2016-2020
dataTidy <- tidyTrump %>%
filter(year >= 2016) %>%
count(id, word) %>%
cast_sparse(id, word, n)
library(glmnet)
#Filter on Year 2016-2020
dataTidy <- tidyTrump %>%
filter(date >= 2016) %>%
count(id, word) %>%
cast_sparse(id, word, n)
as_tibble(dataTidy)
library(glmnet)
#Filter on Year 2016-2020
dataTidy <- tidyTrump %>%
filter(date >= 2016) %>%
count(id, word) %>%
cast_sparse(id, word, n)
dataTidyRows <- tibble(id = rownames(dataTidy))
trumpTweetsFull <- left_join(dataTidyRows, data)
library(glmnet)
#Filter on Year 2016-2020
dataTidy <- tidyTrump %>%
filter(date >= 2016) %>%
count(id, word) %>%
cast_sparse(id, word, n)
dataTidyRows <- tibble(id = rownames(dataTidy))
data1 <- data %>% mutate(`id`=as.character(`id`))
trumpTweetsFull <- left_join(dataTidyRows, data1)
fit1 <- glmnet(dataTidy, dataTidy$retweets)
fit1 <- glmnet(dataTidy, trumpTweetsFull$retweets)
plot(fit1, xvar = "lambda", label = TRUE)
cvfit <- cv.glmnet(dataTidy, trumpTweetsFull$retweets)
plot(cvfit)
c1 <- coef(cvfit, s = "lambda.min")
sum(c1 != 0)
c2 <- coef(cvfit, s = "lambda.lse")
c2 <- coef(cvfit, s = "lambda.1se")
sum(c2 != 0)
c2 <- coef(cvfit, s = "lambda.1se")
sum(c2 != 0)
print(cvfit)
coef_term <- as.data.frame(as.matrix(c2)) %>%
rename(coef = 1) %>%
filter(coef != 0)
arrange(coef_term, desc(coef))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(sotu)
library(dplyr)
library(stringr)
library(tidytext)
data <- read.csv("twitter/realDonaldTrump-20201106.csv")
#as_tibble(data)
tidyTrump <- data %>%
filter(isRetweet == 'f') %>%
unnest_tokens (input = text, output = "word", token = "tweets", strip_url = TRUE) %>%
anti_join(stop_words, by = "word") %>%
filter(!str_detect(word, 'realdonaldtrump')) %>%
filter(!str_detect(word, 'donald')) %>%
filter(!str_detect(word, 'trump')) %>%
filter(!str_detect(word, '[:space:]')) %>%
filter(!str_detect (word, "@")) %>%
filter(!str_detect(word, "https")) %>%
filter(!str_detect (word, "&amp")) %>%
filter (!str_detect(word, "amp"))
as_tibble(tidyTrump)
tidyTrump %>%
count (word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes (x=reorder (word, n), y=n)) +
geom_col() +
coord_flip() +
labs(x="Word", y="Count",
title="Trump Tweets") +
scale_fill_brewer (palette="Setl")
tidyTrump_2015_2020 <- tidyTrump %>% mutate(year=substr(tidyTrump$date,1,4)) %>%
filter(year %in% c('2015','2016','2017','2018','2019','2020'))
as_tibble(tidyTrump_2015_2020)
tidyTrump_2015_2020 %>%
group_by(year) %>%
count (word, sort=TRUE) %>%
top_n(20) %>%
ggplot(aes (x=reorder_within(word, n, year), y=n, fill = year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~year, scales="free") +
coord_flip() +
labs(x="Words", y="Count",
title="Trumps Most common words by year") +
scale_fill_brewer (palette="Set1") +
scale_x_reordered()
tweetsTrumpTidy_2015_2020_tf_idf <- tidyTrump_2015_2020 %>%
count(year, word, sort=TRUE) %>%
bind_tf_idf(term=word, document=year, n=n)
arrange (tweetsTrumpTidy_2015_2020_tf_idf, desc(tf_idf))
tweetsTrumpTidy_2015_2020_tf_idf %>%
group_by(year) %>%
top_n(20, wt=tf_idf) %>%
ggplot(aes (x=reorder_within(word, tf_idf, year), y=tf_idf, fill-year)) +
geom_col(show.legend=FALSE) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank()) +
facet_wrap(~year, scales="free") +
coord_flip() +
labs(x="Word", y="TF-IDF",
title="Top 20 most frequent tweets",
fill="Time Period") +
scale_fill_brewer(palette="Set1") +
scale_x_reordered() +
theme(axis.text.y = element_text(size=8))
tweetsTrumpTidy_2015_2020_tf_idf <- tidyTrump_2015_2020 %>%
count(year, word, sort=TRUE) %>%
bind_tf_idf(term=word, document=year, n=n)
arrange (tweetsTrumpTidy_2015_2020_tf_idf, desc(tf_idf))
tweetsTrumpTidy_2015_2020_tf_idf %>%
group_by(year) %>%
top_n(20, wt=tf_idf) %>%
ggplot(aes (x=reorder_within(word, tf_idf, year), y=tf_idf, fill-year)) +
geom_col(show.legend=FALSE) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank()) +
facet_wrap(~year, scales="free") +
coord_flip() +
labs(x="Word", y="TF-IDF",
title="Top 20 most frequent tweets",
fill="Time Period") +
scale_fill_brewer(palette="Set1") +
scale_x_reordered() +
theme(axis.text.y = element_text(size=8))
library(glmnet)
#Filter on Year 2016-2020
dataTidy <- tidyTrump %>%
filter(date >= 2016) %>%
count(id, word) %>%
cast_sparse(id, word, n)
dataTidyRows <- tibble(id = rownames(dataTidy))
data1 <- data %>% mutate(`id`=as.character(`id`))
trumpTweetsFull <- left_join(dataTidyRows, data1)
fit1 <- glmnet(dataTidy, trumpTweetsFull$retweets)
plot(fit1, xvar = "lambda", label = TRUE)
cvfit <- cv.glmnet(dataTidy, trumpTweetsFull$retweets)
plot(cvfit)
best.lambda <- crossv$lambda.min
best.lambda <- cvfit$lambda.min
best.lambda <- cvfit$lambda.min
print(best.lambda)
coef_term <- as.data.frame(as.matrix(c2)) %>%
rename(coef = 1) %>%
filter(coef != 0)
arrange(coef_term, desc(coef))
shiny::runApp('D:/Data Science Masters/Work/Lazer Lab/Misinformation Dashboard/covid-tweets-dashboard')
shiny::runApp('D:/Data Science Masters/Work/Lazer Lab/Misinformation Dashboard/covid-tweets-dashboard - original')
install.packages('rsconnect')
install.packages('rsconnect')
rsconnect::setAccountInfo(name='sumukh-vasisht',
token='7BF3B488F18A55EDDC74A1EF4B9F3C83',
secret='XiY3+ThvThz2MOsx8jawkv9WU9Ja4VQlcd17Oz9L')
shiny::runApp('D:/Data Science Masters/Work/Lazer Lab/Misinformation Dashboard/covid-tweets-dashboard - original')
rsconnect::setAccountInfo(name='lazerlab',
token='9D0F2E1729409E5D5BFC7CD3AA11045E',
secret='WLsK8jgAcTriuzqcUgNiWZJ03P/LIIkJdP9m07uj')
shiny::runApp('D:/Data Science Masters/Work/Lazer Lab/Misinformation Dashboard/covid-tweets-dashboard - original')
runApp('D:/Data Science Masters/Work/Lazer Lab/Misinformation Dashboard/covid-tweets-dashboard - original')
shiny::runApp('D:/Data Science Masters/Work/Lazer Lab/Misinformation Dashboard/covid-tweets-dashboard - original')
shiny::runApp('D:/Data Science Masters/Work/Lazer Lab/Misinformation Dashboard/covid-tweets-dashboard - original')
shiny::runApp('D:/Data Science Masters/Work/Lazer Lab/RussiaUkraine')
